{"cells":[{"cell_type":"code","execution_count":1,"id":"8a1612ef","metadata":{"id":"8a1612ef"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"id":"4e736c96","metadata":{"id":"4e736c96"},"outputs":[],"source":["# import umap\n","# import umap.plot"]},{"cell_type":"code","execution_count":2,"id":"35bbe173","metadata":{"id":"35bbe173"},"outputs":[],"source":["import pickle"]},{"cell_type":"code","execution_count":3,"id":"063e45b9","metadata":{"id":"063e45b9"},"outputs":[],"source":["from sklearn.decomposition import LatentDirichletAllocation"]},{"cell_type":"code","execution_count":4,"id":"5647b75a","metadata":{"id":"5647b75a"},"outputs":[],"source":["from sklearn.mixture import GaussianMixture"]},{"cell_type":"code","execution_count":5,"id":"dbe06814","metadata":{"id":"dbe06814"},"outputs":[],"source":["from sklearn.metrics import silhouette_score"]},{"cell_type":"code","execution_count":6,"id":"261cda5e","metadata":{"id":"261cda5e"},"outputs":[],"source":["import matplotlib.pyplot as plt\n"]},{"cell_type":"code","execution_count":7,"id":"992e2e2b","metadata":{"id":"992e2e2b"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers"]},{"cell_type":"code","execution_count":8,"id":"77115176","metadata":{"id":"77115176"},"outputs":[],"source":["class Sampling(layers.Layer):\n","\n","    def call(self, inputs):\n","        z_mean, z_log_var = inputs\n","        batch = tf.shape(z_mean)[0]\n","        dim = tf.shape(z_mean)[1]\n","        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n","\n","        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n","\n","class VAE(keras.Model):\n","    def __init__(self, encoder, decoder, **kwargs):\n","        super().__init__(**kwargs)\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n","        self.reconstruction_loss_MSE_tracker = keras.metrics.Mean(\n","            name=\"reconstruction_loss_MSE\"\n","        )\n","        self.reconstruction_loss_binary_tracker = keras.metrics.Mean(\n","            name=\"reconstruction_loss_binary\"\n","        )\n","        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n","\n","    @property\n","    def metrics(self):\n","        return [\n","            self.total_loss_tracker,\n","            self.reconstruction_loss_MSE_tracker,\n","            self.reconstruction_loss_binary_tracker,\n","            self.kl_loss_tracker,\n","        ]\n","\n","    def train_step(self, data):\n","        with tf.GradientTape() as tape:\n","            z_mean, z_log_var, z = self.encoder(data)\n","            reconstruction = self.decoder(z)\n","            reconstruction_loss_MSE = tf.reduce_mean(\n","                tf.reduce_sum(\n","                    keras.losses.MeanSquaredError()(data[:,0:2], reconstruction[:,0:2])\n","                )\n","            )\n","            reconstruction_loss_binary = tf.reduce_mean(\n","                tf.reduce_sum(\n","                    keras.losses.BinaryCrossentropy()(data[:,2:], reconstruction[:,2:])\n","                )\n","            )\n","            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n","            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n","\n","            # total_loss = 0.2*reconstruction_loss_MSE + 0.4*reconstruction_loss_binary + 0.4*kl_loss\n","            total_loss = reconstruction_loss_MSE + reconstruction_loss_binary + kl_loss\n","\n","        grads = tape.gradient(total_loss, self.trainable_weights)\n","        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n","        self.total_loss_tracker.update_state(total_loss)\n","        self.reconstruction_loss_MSE_tracker.update_state(reconstruction_loss_MSE)\n","        self.reconstruction_loss_binary_tracker.update_state(reconstruction_loss_binary)\n","        self.kl_loss_tracker.update_state(kl_loss)\n","        return {\n","            \"loss\": self.total_loss_tracker.result(),\n","            \"reconstruction_loss_MSE\": self.reconstruction_loss_MSE_tracker.result(),\n","            \"reconstruction_loss_binary\": self.reconstruction_loss_binary_tracker.result(),\n","            \"kl_loss\": self.kl_loss_tracker.result(),\n","        }"]},{"cell_type":"code","execution_count":9,"id":"892945e5","metadata":{"id":"892945e5"},"outputs":[],"source":["def get_user_history(df):\n","    gr = df.groupby(['order_requests', 'avatar_id'])\n","\n","    new_df = pd.DataFrame()\n","    for _, v in gr:\n","        new_df = new_df.append(v.head(1)[['order_requests', 'avatar_id']])\n","    new_df['user_history'] = new_df.groupby('avatar_id').cumcount()\n","\n","    df = pd.merge(df, new_df, how='inner', on=['order_requests', 'avatar_id'])\n","\n","    return df"]},{"cell_type":"code","execution_count":12,"id":"242a3085","metadata":{"id":"242a3085"},"outputs":[],"source":["def map_hotel_group(group):\n","    groups = {'Boss Western': 'Boss_Western_Group', 'Accar Hotels': 'Accar_Hotels', 'Independant': 'Independant_Group',\n","              'Yin Yang': 'Yin_Yang', 'Chillton Worldwide': 'Chillton_Worldwide',\n","              'Morriott International': 'Morriott_International'}\n","\n","    return groups[group]\n","\n","def map_hotel_brand(brand):\n","    brands = {'J.Halliday Inn': 'J_Halliday_Inn', 'Marcure': 'Marcure', 'Independant': 'Independant_Brand',\n","              'Ibas': 'Ibas', 'Safitel': 'Safitel', '8 Premium': '8_Premium', 'Tripletree': 'Tripletree',\n","              'CourtYord': 'CourtYord', 'Royal Lotus': 'Royal_Lotus', 'Boss Western': 'Boss_Western_Brand',\n","              'Corlton': 'Corlton', 'Navatel': 'Navatel', 'Ardisson': 'Ardisson', 'Morriot': 'Morriot',\n","              'Chill Garden Inn': 'Chill_Garden_Inn', 'Quadrupletree': 'Quadrupletree'}\n","\n","    return brands[brand]\n","\n","def load_full_feature_set():\n","    # load data\n","    queries = pd.read_csv('all_queries.csv')\n","    prices = pd.read_csv('all_prices.csv')\n","    hotels = pd.read_csv('features_hotels.csv')\n","    test = pd.read_csv('test_set.csv')\n","\n","    # drop query duplicates\n","    # queries = queries.drop_duplicates(subset=['language', 'city', 'date', 'mobile'])\n","    queries = queries.rename(columns={'queryId': 'order_requests'})\n","    prices = prices.rename(columns={'queryId': 'order_requests'})\n","    # queries = get_user_history(queries)\n","\n","    ### X_TRAIN ###\n","    # merge queries, prices and hotel_features\n","    X_train = pd.merge(queries, prices, how='inner', on='order_requests')\n","    X_train = pd.merge(X_train, hotels, how='inner', on='hotel_id')\n","    X_train = X_train.drop(columns='city_y')\n","    X_train = X_train.rename(columns={'city_x': 'city'})\n","\n","    # brand and group correction\n","    X_train['brand'] = X_train.apply(lambda x: map_hotel_brand(x['brand']), axis=1)\n","    X_train['group'] = X_train.apply(lambda x: map_hotel_group(x['group']), axis=1)\n","\n","    X_train = X_train.drop(columns=['avatar_name'])\n","    \n","    # feature ordering to match test set\n","    X_train = X_train[['order_requests', 'avatar_id', 'city', 'language', 'date', 'mobile',\n","                       # 'user_history',\n","                       'stock', 'group', 'brand', 'parking', 'pool', 'hotel_id',\n","                       'children_policy', 'price']]\n","    ### X_TRAIN ###\n","    \n","    \n","    ### X_TEST ###\n","    # merge test_set with hotel_features\n","    # test = get_user_history(test)\n","    X_test = pd.merge(test, hotels, how='inner', on='hotel_id')\n","    X_test = X_test.drop(columns='city_y')\n","    X_test = X_test.rename(columns={'city_x': 'city'})\n","\n","    # brand and group correction\n","    X_test['brand'] = X_test.apply(lambda x: map_hotel_brand(x['brand']), axis=1)\n","    X_test['group'] = X_test.apply(lambda x: map_hotel_group(x['group']), axis=1)\n","\n","    X_test = X_test[['index', 'order_requests', 'avatar_id', 'city', 'language', 'date', 'mobile',\n","                     # 'user_history',\n","                     'stock', 'group', 'brand', 'parking', 'pool', 'hotel_id',\n","                     'children_policy']]\n","    ### X_TEST ###\n","    \n","    return X_train, X_test"]},{"cell_type":"code","execution_count":13,"id":"5096c884","metadata":{"id":"5096c884"},"outputs":[],"source":["X_train, X_test = load_full_feature_set()\n","\n","X_train = X_train.set_index(['order_requests', 'avatar_id', 'hotel_id'])\n","X_test = X_test.set_index(['order_requests', 'avatar_id', 'hotel_id'])\n","\n","y_train = X_train.pop('price')\n","test_idxs = X_test.pop('index')"]},{"cell_type":"code","execution_count":14,"id":"01a24658","metadata":{"id":"01a24658"},"outputs":[],"source":["categories = ['city', 'language', 'mobile', 'group', 'brand', 'parking', 'pool', 'children_policy']\n","\n","X_train = pd.get_dummies(X_train, columns=categories)\n","X_test = pd.get_dummies(X_test, columns=categories)"]},{"cell_type":"code","execution_count":15,"id":"7e06a081","metadata":{"id":"7e06a081"},"outputs":[],"source":["# X = X_train.sample(200000, random_state=0)\n","X = X_train.copy()"]},{"cell_type":"code","execution_count":null,"id":"4d9197d6","metadata":{"id":"4d9197d6"},"outputs":[],"source":["X_index = X.index"]},{"cell_type":"code","execution_count":16,"id":"3e81ed8e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":865,"status":"ok","timestamp":1675213713302,"user":{"displayName":"Beltrán Castro","userId":"01274272060099097138"},"user_tz":-60},"id":"3e81ed8e","outputId":"dbd3e8af-13b8-46cd-a437-360d214d105c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"encoder\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 69)]         0           []                               \n","                                                                                                  \n"," dense (Dense)                  (None, 64)           4480        ['input_1[0][0]']                \n","                                                                                                  \n"," dense_1 (Dense)                (None, 32)           2080        ['dense[0][0]']                  \n","                                                                                                  \n"," dense_2 (Dense)                (None, 16)           528         ['dense_1[0][0]']                \n","                                                                                                  \n"," dense_3 (Dense)                (None, 12)           204         ['dense_2[0][0]']                \n","                                                                                                  \n"," z_mean (Dense)                 (None, 10)           130         ['dense_3[0][0]']                \n","                                                                                                  \n"," z_log_var (Dense)              (None, 10)           130         ['dense_3[0][0]']                \n","                                                                                                  \n"," sampling (Sampling)            (None, 10)           0           ['z_mean[0][0]',                 \n","                                                                  'z_log_var[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 7,552\n","Trainable params: 7,552\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Model: \"decoder\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_2 (InputLayer)           [(None, 10)]         0           []                               \n","                                                                                                  \n"," dense_4 (Dense)                (None, 12)           132         ['input_2[0][0]']                \n","                                                                                                  \n"," dense_5 (Dense)                (None, 16)           208         ['dense_4[0][0]']                \n","                                                                                                  \n"," dense_6 (Dense)                (None, 32)           544         ['dense_5[0][0]']                \n","                                                                                                  \n"," dense_7 (Dense)                (None, 64)           2112        ['dense_6[0][0]']                \n","                                                                                                  \n"," tf.__operators__.getitem (Slic  (None, 2)           0           ['dense_7[0][0]']                \n"," ingOpLambda)                                                                                     \n","                                                                                                  \n"," tf.__operators__.getitem_1 (Sl  (None, 62)          0           ['dense_7[0][0]']                \n"," icingOpLambda)                                                                                   \n","                                                                                                  \n"," dense_8 (Dense)                (None, 2)            6           ['tf.__operators__.getitem[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," dense_9 (Dense)                (None, 67)           4221        ['tf.__operators__.getitem_1[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," tf.concat (TFOpLambda)         (None, 69)           0           ['dense_8[0][0]',                \n","                                                                  'dense_9[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 7,223\n","Trainable params: 7,223\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["input_dim = X.shape[1]\n","latent_dim = 10\n","\n","######################################################\n","# Encoder Architecture\n","######################################################\n","encoder_inputs = keras.Input(shape=input_dim)\n","x = layers.Dense(64, activation=tf.nn.leaky_relu, kernel_initializer='glorot_normal', bias_initializer='zeros')(encoder_inputs)\n","x = layers.Dense(32, activation=tf.nn.leaky_relu, kernel_initializer='glorot_normal', bias_initializer='zeros')(x)\n","x = layers.Dense(16, activation=tf.nn.leaky_relu, kernel_initializer='glorot_normal', bias_initializer='zeros')(x)\n","x = layers.Dense(12, activation=tf.nn.leaky_relu, kernel_initializer='glorot_normal', bias_initializer='zeros')(x)\n","######################################################\n","# Sampling Layer\n","######################################################\n","z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n","z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n","z = Sampling()([z_mean, z_log_var])\n","\n","encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n","encoder.summary()\n","\n","######################################################\n","# Decoder Architecture\n","######################################################\n","latent_inputs = keras.Input(shape=(latent_dim,))\n","x = layers.Dense(12, activation=tf.nn.leaky_relu, kernel_initializer='glorot_normal', bias_initializer='zeros')(latent_inputs)\n","x = layers.Dense(16, activation=tf.nn.leaky_relu, kernel_initializer='glorot_normal', bias_initializer='zeros')(x)\n","x = layers.Dense(32, activation=tf.nn.leaky_relu, kernel_initializer='glorot_normal', bias_initializer='zeros')(x)\n","x = layers.Dense(64, activation=tf.nn.leaky_relu, kernel_initializer='glorot_normal', bias_initializer='zeros')(x)\n","x1 = x[:,0:2]\n","x2 = x[:,2:]\n","x1 = layers.Dense(2, activation='relu')(x1)\n","x2 = layers.Dense(input_dim-2, activation='sigmoid')(x2)\n","\n","decoder_outputs = tf.concat([x1, x2], 1)\n","decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n","decoder.summary()"]},{"cell_type":"code","execution_count":17,"id":"06dea9a1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2818004,"status":"ok","timestamp":1675216533888,"user":{"displayName":"Beltrán Castro","userId":"01274272060099097138"},"user_tz":-60},"id":"06dea9a1","outputId":"b721cc41-e8d7-4881-ff28-ca3c5e0407c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/40\n","9346/9346 [==============================] - 72s 5ms/step - loss: 125.1724 - reconstruction_loss_MSE: 17.4863 - reconstruction_loss_binary: 0.2590 - kl_loss: 12.3094\n","Epoch 2/40\n","9346/9346 [==============================] - 39s 4ms/step - loss: 6.5669 - reconstruction_loss_MSE: 1.3441 - reconstruction_loss_binary: 0.2493 - kl_loss: 4.7647\n","Epoch 3/40\n"," 374/9346 [>.............................] - ETA: 36s - loss: 6.1314 - reconstruction_loss_MSE: 1.2124 - reconstruction_loss_binary: 0.2486 - kl_loss: 4.5880"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[17], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39m# vae.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, clipnorm=1.0))\u001b[39;00m\n\u001b[0;32m      3\u001b[0m vae\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m))\n\u001b[1;32m----> 4\u001b[0m vae\u001b[39m.\u001b[39;49mfit(X, epochs\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m Z_mean, Z_log_var, Z \u001b[39m=\u001b[39m vae\u001b[39m.\u001b[39mencoder\u001b[39m.\u001b[39mpredict(X)\n\u001b[0;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mlatent variables are ready to used\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[1;32mc:\\Users\\hp\\miniconda3\\envs\\pgm_project\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[1;32mc:\\Users\\hp\\miniconda3\\envs\\pgm_project\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[1;32mc:\\Users\\hp\\miniconda3\\envs\\pgm_project\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[1;32mc:\\Users\\hp\\miniconda3\\envs\\pgm_project\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[1;32mc:\\Users\\hp\\miniconda3\\envs\\pgm_project\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[1;32mc:\\Users\\hp\\miniconda3\\envs\\pgm_project\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[1;32mc:\\Users\\hp\\miniconda3\\envs\\pgm_project\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[1;32mc:\\Users\\hp\\miniconda3\\envs\\pgm_project\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n","File \u001b[1;32mc:\\Users\\hp\\miniconda3\\envs\\pgm_project\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["vae = VAE(encoder, decoder)\n","# vae.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, clipnorm=1.0))\n","vae.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001))\n","vae.fit(X, epochs=40, batch_size=64)\n","\n","Z_mean, Z_log_var, Z = vae.encoder.predict(X)\n","\n","print(\"latent variables are ready to used\")"]},{"cell_type":"code","execution_count":null,"id":"b8567e91","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1675216533890,"user":{"displayName":"Beltrán Castro","userId":"01274272060099097138"},"user_tz":-60},"id":"b8567e91","outputId":"0beb320d-0388-49f4-9bcf-1625f309ce28"},"outputs":[{"data":{"text/plain":["array([[ 1.1627884 ,  0.36382967, -1.9693272 , ...,  0.51040834,\n","        -1.8198822 , -0.18090591],\n","       [-0.28934494, -0.94989425,  2.0511403 , ...,  0.62608874,\n","         0.23161753,  0.82270646],\n","       [ 1.8215923 , -0.15188862, -0.2334091 , ...,  1.3688658 ,\n","         1.577463  , -0.85774934],\n","       ...,\n","       [-0.2635221 ,  0.2726285 ,  2.450029  , ..., -1.2220204 ,\n","        -0.00587447,  0.44881904],\n","       [-0.48593444,  2.136825  ,  2.4633138 , ...,  1.555804  ,\n","         0.10123453, -0.8165832 ],\n","       [ 0.1999354 , -0.02391236,  2.4473205 , ..., -0.5206073 ,\n","         0.01083857,  0.9335608 ]], dtype=float32)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["Z"]},{"cell_type":"code","execution_count":null,"id":"65edfe47","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1675216533890,"user":{"displayName":"Beltrán Castro","userId":"01274272060099097138"},"user_tz":-60},"id":"65edfe47","outputId":"97ec1899-2ec1-4b3a-c063-4131f5163473"},"outputs":[{"data":{"text/plain":["(598114, 10)"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["Z.shape"]},{"cell_type":"code","execution_count":null,"id":"zw8wXQ8QqCS5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1675216533892,"user":{"displayName":"Beltrán Castro","userId":"01274272060099097138"},"user_tz":-60},"id":"zw8wXQ8QqCS5","outputId":"b9673070-c7aa-420d-a055-e673f98b9069"},"outputs":[{"data":{"text/plain":["array([[ 2.3137587e-03,  1.0750362e-03, -1.2315954e+00, ...,\n","         3.9957291e-03, -4.7166005e-04,  3.7779240e-03],\n","       [ 1.3884320e-04, -6.3873366e-03,  2.0385087e+00, ...,\n","         1.3800473e-03, -7.3623345e-03, -9.0158265e-03],\n","       [-3.3529769e-03, -3.1204445e-03, -2.1445733e-01, ...,\n","         2.0309589e-03,  4.1578157e-04,  1.3662793e-03],\n","       ...,\n","       [-1.7632721e-03, -5.5003604e-03,  2.4500885e+00, ...,\n","        -6.9552334e-04, -1.0520962e-02, -1.0599390e-02],\n","       [-1.7310954e-03, -5.5810427e-03,  2.4501286e+00, ...,\n","        -6.3820928e-04, -1.0475635e-02, -1.0613852e-02],\n","       [-1.8533729e-03, -5.3540058e-03,  2.4495959e+00, ...,\n","        -8.8807894e-04, -1.0659224e-02, -1.0468761e-02]], dtype=float32)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["Z_mean"]},{"cell_type":"code","execution_count":null,"id":"YyXk7v09qDgl","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1675216533893,"user":{"displayName":"Beltrán Castro","userId":"01274272060099097138"},"user_tz":-60},"id":"YyXk7v09qDgl","outputId":"20ff604e-da65-4c45-e2ff-f48e98ef4dc6"},"outputs":[{"data":{"text/plain":["array([[ 4.3404463e-04,  3.4793017e-03, -2.6241369e+00, ...,\n","        -2.1427544e-04,  5.3302320e-03,  9.2198083e-04],\n","       [-7.6318458e-03, -1.7413255e-02, -8.9611855e+00, ...,\n","        -1.1936810e-02, -2.1525843e-02,  1.4607872e-02],\n","       [-3.2425406e-03, -2.3295602e-03, -5.7142162e+00, ...,\n","        -2.7391429e-03, -1.4571417e-02,  6.7619737e-03],\n","       ...,\n","       [-9.8784845e-03, -1.7779309e-02, -8.9979858e+00, ...,\n","        -1.5130653e-02, -2.2583274e-02,  1.6808735e-02],\n","       [-9.8624537e-03, -1.7834419e-02, -9.0011520e+00, ...,\n","        -1.5099277e-02, -2.2615775e-02,  1.6815709e-02],\n","       [-9.9891908e-03, -1.7701836e-02, -8.9962368e+00, ...,\n","        -1.5264818e-02, -2.2556579e-02,  1.6750272e-02]], dtype=float32)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["Z_log_var"]},{"cell_type":"code","execution_count":null,"id":"zgo87izUhehR","metadata":{"id":"zgo87izUhehR"},"outputs":[],"source":["np.save('10d/Z_10d.npy', Z)"]},{"cell_type":"code","execution_count":null,"id":"W6YcpMpGhk2q","metadata":{"id":"W6YcpMpGhk2q"},"outputs":[],"source":["np.save('10d/Z_mean_10d.npy', Z_mean)"]},{"cell_type":"code","execution_count":null,"id":"IubLV9dXhlVm","metadata":{"id":"IubLV9dXhlVm"},"outputs":[],"source":["np.save('10d/Z_log_var_10d.npy', Z_log_var)"]},{"cell_type":"code","execution_count":null,"id":"OpU0s1j9iA8i","metadata":{"id":"OpU0s1j9iA8i"},"outputs":[],"source":["X.to_csv('10d/original_data.csv')"]},{"cell_type":"code","execution_count":null,"id":"7BPPCbp4icxe","metadata":{"id":"7BPPCbp4icxe"},"outputs":[],"source":["Z_df = pd.DataFrame(data=Z, index=X_index)"]},{"cell_type":"code","execution_count":null,"id":"0UXjspI6iieQ","metadata":{"id":"0UXjspI6iieQ"},"outputs":[],"source":["Z_df.to_csv('10d/Z_df.csv')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1YXyYPaXUIc5V_KtX2yPFalGcUwNctYAb","timestamp":1675208899010}]},"gpuClass":"standard","kernelspec":{"display_name":"pgm_project","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"vscode":{"interpreter":{"hash":"6251d9e1bdd53d4009af8fcf01fbbac9d22b063c1b2fd951e42e1ab4ca41ae48"}}},"nbformat":4,"nbformat_minor":5}
